## 1
广告可以运作其实与我们实际的教育模式是相似的，用户就是学生，媒体就是学校，广告主其实就是政府（或者就是数据分析）。
人群可分为说服型、确认型、沉睡型、勿扰型。
在营销有成本的条件下，我们这时应该减少在这三个人群中的营销投入，

## 2
先讲CATE以及uplift
如果我们能估计出准确的cate时，即知道哪类人群对于营销的提升效果最好，并针对这类人群进行营销，那么我们的这个营销的收益也一定是最大化的，这其实就是我们实验室常常关注的个性化是一致的。
用处主要为：
1、估计不同人群之中对于营销的个性化差异，避免对于三类人群进行营销。
2、根据异质性治疗效果，在成本有限的条件下如何进行一个干预的分配。
## 4
其中第一步是根据一般化的公式得到; 第二步由可忽略性(ignorabilityde)得到;第三步则是根据2 把潜在结果飞(1)或(0)替换成观测到的 YATE(1)式定义依赖于不可以完全被观测的潜在结果，而经过推导后的ATE计算仅仅依赖于观测到的结果，我们就说平均因果效应(ATE)是可识别的，

我们后续的CATE是基于潜在结果理论进行设计的，现在我们看一下ATE与CATE的关系。

## 5
介绍机器学习预测模型与因果预测模型的区别，体现因果森林预测模型的不容易。

Uplift的讲解顺序的难度也是从简单到难的，

Metalearner的优点：利用了既有预测算法的预测能力，方便易实现，缺点：不直接建模uplift，很难得到一个完美的效果

元学习器是一种思想，通过利用现成的预测性机器学习方法来解决我们迄今为止一直在研究的相同问题的简单方法：估计 CATE。
同样，它们中没有一种是最好的，每一种都有其弱点，这些方法在很大程度上取决于具体情况。
不仅如此，元学习器部署的预测性 ML 模型可以从逻辑回归和提升决策树到神经网络等等等。元学习器的成功也在很大程度上取决于它使用何种机器学习方法作为其组成部分。很多时候，您只需尝试多种不同的方法，看看哪种方法最有效。

## 6 s-learner
优点
	本章的其他学习器只能处理离散情况
	Single model能利用分类算法的优势，同时减少TLEARNER引起的双模型误差累积。
	利用了全部的数据进行训练，训练的样本增加，使得模型学习的更加充分，提高了模型的泛化能力。
缺点
	增量还是间接计算的，仍然存在精度问题。
	当treatment组（T=1）和control组（T=0）的样本分布差异大时，S-Learner也没办法很好处理selection bias 问题。
	s型学习者的主要缺点是它倾向于将治疗效果偏向于零。由于s -学习者通常使用正则化机器学习模型，因此正则化可以限制估计的治疗效果。如果治疗相对于其他协变量在解释结果时的影响非常弱，s -学习者可以完全抛弃治疗变量。模型正则化越大
	其次，S-Learner 实现简单，当协变量X维度高时，干预变量T 容易被埋没，Treatment 的作用可能会被模型忽视掉。由于模型选择特征是自动的，没有明确关注T变量的地位，从而容易忽略异质性的因果效应，因为无论w=0或1，均可能得到响应的结果

## 7 s-learner实验
为了评估这个模型，我们将查看测试集中的累积增益曲线。我还绘制了训练集的增益曲线。由于训练集是有偏差的，因此这条曲线无法说明模型是否优秀，但它可以指出我们是否过度拟合了训练集。当这种情况发生时，训练集中的曲线就会超高。如果你想看看这种情况，可以尝试将 max_depth 参数从 3 改为 20。

```python
from lightgbm import LGBMRegressor  
np.random.seed(123)  
s_learner = LGBMRegressor(max_depth=3, min_child_samples=30)  
s_learner.fit(train[X+[T]], train[y]);
s_learner_cate_train = (s_learner.predict(train[X].assign(**{T: 1})) -  
                        s_learner.predict(train[X].assign(**{T: 0})))  
  
s_learner_cate_test = test.assign(  
    cate=(s_learner.predict(test[X].assign(**{T: 1})) - # predict under treatment  
          s_learner.predict(test[X].assign(**{T: 0}))) # predict under control  
)
```
## 8 t-learner的优缺点
优点：
确实关注了两种治疗变量。
实现简单明了，容易实现，实现方法多。

缺点：
数据利用效率低，T-Learner的两个组件都只用了部份的数据，Tlearner只使用了部分数据。
差分建模，训练是彼此独立的,它会导致一个误差累积,最终的cate的误差较大。
无法解决selection bias问题，当有足够无偏的随机样本（即满足 randomized control trial; _RCT_）做训练时，是个不错的选择。但在实际场景中，随机样本是很“贵”的甚至无法采集的，对于不满足RCT条件的数据机，T-Learner无法解决 selection bias问题，导致预估的因果效应可能会存在很大的偏差。另外，存在数据利用率低的问题，独立训练也会导致最终ITE预估结果方差大。

## 9 X-learner介绍

1、r0与r1都是r的估计量，选择g（x)是为了将这些估计量组合成一个改进的估计量r;
2、根据我们的经验，我们观察到使用g（x）的倾向得分的估计值是很好的，这样g=e，如果实验组的数量与对照组的数量相比非常大或非常小，那么选择g=1或0也是有意义的。
Xlearner最后相当于是对uplift直接进行了一个建模，

## 10 X-learner的优缺点

但是建立了太多模型，累积误差依然是存在的。
根据前边的无混淆假设以及倾向性得分，假如对于所有的样本X，他们的的倾向性得分是一样的，那么选择是没有偏差的，也就是随机实验。

## 11 X-learner的论文讲解

总结来说，如果有一个横型是错误地估算了干预效果;而另一个模型是正确的，因为你正确地估算了那些值。现在，你需要一种方法把这两个模型结合起来，同时给予正确模型更大的权重，为此，你可以使用倾向得分模型。

原理在于，由于干预单元非常少，è(z)非常小，这使得错误CATE模型产(X)-o 的权重非常小。相比之下，1-è(r)接近1，所以你会给正确CATE模型产(X)1更多的权重。更一般地说，使用倾向得分的加权平均将有利于使用更多数掘训练的声模型得到的干预效果估算。

## KNN
Knn在维数情况较多的情况下，容易出现维数灾难，
在所有维度上都相似的邻居，但只有两个维度很重要

## 12 因果树的估计
当叶子足够小时，如果倾向得分函数是一个连续的函数，那么在比较小的叶子里，他们的倾向性得分都差不多，那么就可以认为YI与wi是随机实验。
## 13 因果树的分裂规则
KL散度、欧氏距离、卡方散度

最后我们定义一下 D(P:Q A)这个conditional divergence。这里我们补充一下，a是 A-种outcome， N 是样本数，N(a)是按照 A 分裂的结果是 a 剩下的样本数，我们有

## 14 诚实树的构建
然而，我们的结果确实要求单个树满足一个相当强的条件，我们称之为诚实：如果对于每个训练样本 i，一棵树只使用响应 Yi 使用（5）来估计叶内处理效应 τ 或决定在何处进行拆分，而不是两者兼用，那么这棵树就是诚实的。
我们注意到，样本拆分程序有时被批评为效率低下，因为它们在估计程序的每一步都 "浪费 "了一半的训练数据。然而，在我们的案例中，森林子抽样机制使我们能够在不浪费任何数据的情况下实现诚信，因为我们在每个子样本上都重新随机化了 I/J 数据的分割。
因此，虽然没有一个数据点可以用于单棵树的分裂选择和树叶估计，但每个数据点都将参与到 I 和 J 样本树中，并将用于指定森林的结构和治疗效果估计。虽然我们考虑双样本树的最初动机是消除偏差，从而实现置信区间居中，但我们发现在实践中，双样本树在均方误差方面也比标准随机森林有所改进。

一个树可能学的不是很好但是，如果我学很多树，做一个平均，平均完以后的树比单一的树会更好一些。
## 14 因果森林的六大条件

1、为了实现点wise一致性，我们必须假设条件期望函数E[Y(0)|X=x]和E[Y(1)|X=x]都是Lipschitz连续的。这意味着当我们改变输入变量X的值时，输出变量Y在未接受处理（Y(0)）和接受处理（Y(1)）两种状态下的条件平均值的变化是平滑且有界的，即它们的变化率有一个全局上界。
在估计异质处理效应时，这一假设确保了无论我们关注的数据点x处于特征空间的哪个位置，通过因果森林方法得到的处理效应估计将随着样本量的增加逐渐趋近于真实的处理效应值。换句话说，只有当这两个条件期望函数具备Lipschitz连续性，我们才能确保因果森林方法在每一点x上都能有效地估计出精确的个体处理效应，并且当样本容量趋于无穷大时，该估计结果将在每一点上都一致收敛于真实值。


## 14 因果森林的缺点
当样本量相对固定而特征维度增加时，每个树的训练数据不足以涵盖特征空间的所有可能性，这可能导致在构建单颗树时对处理效应的估计不够准确，进而造成整个森林集合的预测结果偏向于训练数据的某些局部特征模式，而不是全局真实的处理效应分布。
如果特征维度很高，每棵树的构建过程中由于特征选择的随机性可能导致各棵树之间的预测结果相关性减弱，但同时也可能导致每棵树自身的预测偏差增大。

简而言之，随机森林在高维数据集下容易受到偏差影响，主要是因为在高维空间中模型复杂性与数据稀疏性之间的平衡难以把控，导致模型倾向于过拟合并集中于训练数据中的某些特征模式，而非真实全面地反映处理效应的异质性。

## 14 因果森林的相关文献
异质性治疗效果和最佳目标政策评估。(2023).
用因果森林估计治疗效果：一种应用（2019）（作者根据数据完整的causalforest的编程与实现）
联邦支出对地方犯罪影响的异质性： 因果森林的证据（2019）
使用机器学习进行医疗保健应用的异质性治疗效果估计：教程与基准（预印本）（2021年）
利用机器学习确定治疗目标：家庭能源使用案例（2021年）
违约对投资的异质性影响： 因果森林在企业融资中的应用（2019）
通过绿色创新和城市资源配置实现可持续发展： 来自机器学习的证据（2023）

## 14 Experiment and Data


针对2018年数据，we adjust estimates for the varying propensity scores between early and late cohorts by inverse probability-weighted estimators。
## 14 Experiment and Data
只有2018年晚期学校的GPA在处理组和对照组间存在显著差异,此外估计的倾向得分集中在其批次平均值附近，在各自治疗组和对照组之间保持平衡。

## 基于因果森林的CATE估计
直方图显示，2017年数据的治疗效果约为0至15个百分点，2018年约为5至20个百分点，2017年使用早期和晚期协变量预测的异质性较为相似，2018年使用晚期协变量的预测的CATE比使用研究开始前的估计更加分散。
## CATE的估计效果评估
尽管理论上保证治疗效果的估计值，但在实际中，数据中既含有信息也含有噪声，因此往往需要非常大的样本才能使理论转化为实际。

因此对于更现实的样本量，CATE的估计值往往会被误判。1、对于每个特别的协变量向量，估计值往往会偏向于总体平均治疗效果，这是因为不会有足够多的观察结果与特定目标相似的X。2、对于信噪比较低的数据，抽样会导致不同协变量上的估计治疗效果分布，从而夸大异质性。
对于稳健性，我们基于两种不同的方法来估计异质性治疗效果，即使用我们知道倾向评分在学校组中是恒定的这一事实（“已知”）或估计来自数据的倾向评分对随机化可能存在的问题具有稳健性（“AIPW”）。

我们在表1中的估计值显著大于零（在5%的显著性水平），证明我们的估计值确实捕获了治疗效果异质性。

## CATE异质性状况分析：
尽管不能真正采纳CATE的估计值（应用于单个个体上），但我们仍然可以通过评估哪些单位的治疗效果高于其他单位（应用于群体上），这仍然是可靠的。
我们根据CATE估计值创建此类群体，通过十倍交叉拟合消除偏差

尽管CATE的估计值是没有被校准的，所以无法评估到每个体实际的因果效应，因此难以评估单个观察结果的治疗效果估计值的准确性，但GATES方法告诉我们，可以对于一个足够大的群体构建的平均治疗效果的估计值仍然是无偏的。

表 5：基于 AIPW 估计值的图 3 四分位数治疗效果的配对差异、 
括号内为标准估计值。粗体估算值表示根据单侧检验在 5%水平上具有统计意义的增长。
根据单侧检验，在 5%的水平上具有统计意义。
![[1713169947913.png]]
这些估计值是对各组平均治疗效果的无偏估计值，因为在将单位分配到组的过程中没有使用第k组单位中的结果，因此得出的估计值是各组平均治疗结果的无模型无偏估计值。

## 导致因果效应异质性的主要特征：
所以我们不能单单仅依靠特征重要性

此外异质性的一个潜在驱动因素是学生是否已经注册，对于FAFSA申请没有注册限制，但往往年中辍学的学生在下一学年的重新注册的可能性往往也比较低。

实验中，入学状态一旦可用，对治疗效果往往会有很高的预测性。两组人数固定的情况下，他对治疗效果的分区效果与我们根据治疗效果估计值将学生分组的效果一样好

但结合前图，即使在被录取的学生中，治疗效果也存在额外的异质性。

入学率作为重要的治疗效果调节因素是直观的，但不是机械的，学生也可能会辍学并重新注册，因此对未注册学生提供治疗仍然是有效的。

相反，似乎只有很小的额外异质性，这使得注册本身就已经成为提醒效果的有力替代。
## Causal vs Predictive Targeting

上一节中，发现学生对提醒的反应存在异质性，如何利用学生对提醒的反映的差异性来提高提醒的针对性。

尽管注册学生已经效果很好，但基于特征信息的目标定位还是有意义的，一是因为注册信息还未获得时，我们是否就可以利用对异质性治疗效果的预测来选择学生发送行为信息提醒。其次，即使已注册的学生中，对于提醒信息的反应仍存在一定的异质性。

## Targeting based on Treatment effect estimates：

研究团队开始评估第三部分中提出的异质性处理效应估计值 ˆτ(x) 对于优化提醒策略的价值。传统的评估方式可能是看预测值 ˆτ(x) 如何精确地估计真实的处理效应 τ(x)，而在这里，研究者们采取了一种不同的角度，不再关注预测质量本身，而是量化如果我们只针对学生群体中的一部分进行定向提醒，能够实现总收益的多大部分。
由于异质性效应很大一部分在于是否进行登记，因此我们也考虑，如果优先提醒那些入学登记概率高的学生。
另外，一种自然的想法是优先提醒那些没有治疗情况下最不可能申请经济援助的学生，因为对于这类学生中提示获益的可能性更大，这种政策也很实用，因为只需要对照组信息。
由于f（x)=E[y!x=x,t=0]，，所以我们可以用任何机器学习预测器，在没有实验的情况下根据可用特征预测截止日期前的申报情况，从而高效实施这一政策。
此外我们也可以根据哪些学生最优可能在戒截止日期前申请，对他们排序
## Targeting based on Treatment effect estimates：
我们的估计表明使用因果森林的治疗效果估计，得到了适度的收益，CATE预测：利用早期协变量，针对50%发放治疗，续费率从36.5%提高到41%（实现了65%）的收益，95%的置信区间也表明优于随机测试，后期协变量的表现基本相同，。

对于预测率进行评估，针对入学率预测最高达的学生发送提醒，发现预测入学率的表现不如因果政策，表明治疗效果中存在预测入学率以外的附加变量，后期采用协变量中的入学率进行发放，政策效果与预测入学率相似。

对于学生在没有治疗情况下申请FAFSA的学生预测申报概率，针对低申报概率的学生给予干预，以此作为消极的baseline，发现其表现相较于因果政策差的多，甚至比随机分配差的多，50%学生进行预测，只能从36.5%提高到38.5%，收益不到三分之一。

针对高申报概率的学生进行排序预测，发现对于大部分目标学生而言，积极baseline甚至优于非参数CATE，这可能原因在于不太可能申请FAFSA的学生也不太可能被提醒说服去申请，相反相对较弱的行为鼓励对于那些已经接近申请的学生来说，这种治疗的效果最火爆，因此首先针对那些不可能申报者的基线政策所取得的效果恰恰与预期效果相反。
## 4 Causal vs Predictive Targeting的结论
虽然积极和消极基线政策在事前可能都是合理的，但我们只是通过实验的事后评估才了解到它们的特性。因果关系方法的 优势在于，它可以完全根据协变量与治疗效果之间的经验关系，直接估算出我们可以预期效果良好的政策，从而不必猜测可能效果良好的政策(或明确测试大量政策)。同时，这个例子也说明了利用基线预测的好处。因此，我们将在下文中分析如何让数据决定如何使用基线预测，以获得两全其美的效果。

## 5.1 Model-based targeting from baseline predictions
我们的上述结果表明，为了更好地确定干预措施的目标，而不是盲目地依赖于临时的预测目标规则，对干预措施的因果效应进行建模是非常重要的。同时，这些结果表明，基线预测与因果效应之间存在密切关系。因此，在本节中，我们将提出这样一个问题:我们是否可以将预测信息和因果关系建模有效结合起来，从而更好地确定干预目标?

在这个模型中，β可以被解释为提醒的效果，即减少麻烦成本或增加更新经济援助的感知价值。

具体来说，在平均结果的中间值时，治疗效果最大。也就是说，当申请概率接近于零或1时，治疗的增量影响较小。下文将对这-关系进行更全面的讨论，并在图8中加以说明。
结果中这种简单的政策都优于因果森林的非参数政策，利用这种半参数政策，我们实现了75%的收益，该政策也大大优于基于预测或入学率的目标选择，这表明除了入学率以外还存在可预测的异质性，该政策也优于positive

## 5.2 Targeting based on a hybrid model that adapts to heterogeneity
请注意，尽管平均效用在基线和治疗中是相加的，但logit模型的非线性形式意味着治疗效应以特定方式随基线变化。具体来说，平均结果的中间值时，治疗效果最大
但如果以对数为单位的恒定治疗效果不能很好的近似治疗效果与baseline的关系时，或者当baseline变化无法捕捉额外变化时，模型可能表现不佳。因此考虑采用混合逻辑回归

这种对治疗效果估计值和基线预测值进行参数化的具体方法的优点是，它可以使模型同时捕捉到多种情况

## 5 Improving Targeting by Combining Predictive and Causal Modeling
logit baseline这种简单的logit模型得出的目标定位政策，均优于因果森林的非参数政策，针对一半的学生就带来了75%的收益，也大大优于基于预测和入学率的目标选择，也由于正基线。

当恒定治疗效果不能很好的近似治疗效果与baseline的关系时，或者存在baseline无法捕捉的额外变化时，模型可能表现不佳。因此采用适应异质性混合模型回归。

该混合logit模型的性能与仅使用基线信息的更简单的logit模型相当或略差，同时在整个过程中均优于基于完全非参数估计的目标。

CATE from Baseline一般而言，我们预计这种方法在治疗效果主要随基线变化，并且治疗效果与基线的简单关系可能不足以表达它们时效果良好。

## 模拟研究
λ表示治疗效果异质性的程度。对于λ = 1，该模型仅基于非参数估计值f（x）和f τ（x）进行模拟。对于λ = 0，该模型假设治疗效应在对数优势中是恒定的，而λ > 1对应于额外的变异。